{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "print(X.shape,y.shape)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define network by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrap your network and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6746\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.6699\u001b[0m  0.0310\n",
      "      2        \u001b[36m0.6661\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0285\n",
      "      3        \u001b[36m0.6413\u001b[0m       \u001b[32m0.6900\u001b[0m        0.6629  0.0271\n",
      "      4        0.6417       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6439\u001b[0m  0.0271\n",
      "      5        \u001b[36m0.6327\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0270\n",
      "      6        \u001b[36m0.6299\u001b[0m       0.7000        \u001b[35m0.6289\u001b[0m  0.0268\n",
      "      7        \u001b[36m0.6137\u001b[0m       0.6900        0.6292  0.0269\n",
      "      8        \u001b[36m0.6005\u001b[0m       0.7000        \u001b[35m0.6231\u001b[0m  0.0269\n",
      "      9        \u001b[36m0.5962\u001b[0m       0.7000        \u001b[35m0.6127\u001b[0m  0.0295\n",
      "     10        \u001b[36m0.5876\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6096\u001b[0m  0.0279\n"
     ]
    }
   ],
   "source": [
    "net.fit(X, y)\n",
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7186\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6940\u001b[0m  0.0271\n",
      "      2        \u001b[36m0.6966\u001b[0m       \u001b[32m0.5100\u001b[0m        \u001b[35m0.6869\u001b[0m  0.0273\n",
      "      3        \u001b[36m0.6867\u001b[0m       \u001b[32m0.5650\u001b[0m        \u001b[35m0.6825\u001b[0m  0.0260\n",
      "      4        \u001b[36m0.6830\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.6793\u001b[0m  0.0268\n",
      "      5        \u001b[36m0.6780\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0264\n",
      "      6        0.6790       0.6250        \u001b[35m0.6735\u001b[0m  0.0265\n",
      "      7        \u001b[36m0.6711\u001b[0m       0.6600        \u001b[35m0.6694\u001b[0m  0.0277\n",
      "      8        0.6713       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6661\u001b[0m  0.0303\n",
      "      9        \u001b[36m0.6690\u001b[0m       0.6300        \u001b[35m0.6623\u001b[0m  0.0264\n",
      "     10        \u001b[36m0.6597\u001b[0m       0.6550        \u001b[35m0.6567\u001b[0m  0.0258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "y_proba = pipe.predict_proba(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
