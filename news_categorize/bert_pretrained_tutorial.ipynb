{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\" #これは自分で作らなきゃいけないのかな\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'am', 'a', 'student', '.', '[SEP]']\n",
      "[101, 1045, 2572, 1037, 3076, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "#自分でやってみる\n",
    "\n",
    "# Tokenized input\n",
    "text = r\"I am a student.\" \n",
    "\n",
    "\n",
    "#単語とか活用とかそれらをいい感じに区切ってくれるやつ\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "# [CLF]を先頭につけなければいけない、最後には[SEP]をつけなければ行けないが\n",
    "tokenized_text= ['[CLS]']+tokenized_text+['[SEP]']\n",
    "print(tokenized_text)\n",
    "\n",
    "# 単語番号に変換するためのコンバーター\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(indexed_tokens)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "# テンソル化\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "#文章が一つの場合にもセグメントテンサーが必要なのかも知れない\n",
    "segments_tensors=torch.tensor([0]*len(indexed_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to use `BertModel` to get hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "# BERTのモデルを持ってくる\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cpu')\n",
    "segments_tensors = segments_tensors.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded_layersの中身はもしかして、(bertの層(リスト), トークン数, hidden state) になっている？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cpu')\n",
    "segments_tensors = segments_tensors.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0209, -0.0933, -0.0899,  ..., -0.0462, -0.0979, -0.0050],\n",
       "          [-0.1881,  0.6580,  0.2152,  ...,  0.5455, -0.0858,  0.4080],\n",
       "          [-0.8712, -0.1690,  0.2003,  ...,  0.5357, -0.1346,  0.4288],\n",
       "          ...,\n",
       "          [-0.3829,  0.1071,  0.3474,  ...,  0.6633, -0.5993, -0.4130],\n",
       "          [ 0.4142, -0.1914, -1.1008,  ...,  0.1034,  0.5236, -0.3538],\n",
       "          [-0.2399,  0.0702, -0.6301,  ..., -0.2046,  0.1391,  0.2259]]]),\n",
       " tensor([[[ 0.1202, -0.0804, -0.0579,  ...,  0.1063, -0.1013,  0.0238],\n",
       "          [-0.2258,  0.4770,  0.0755,  ...,  0.1937, -0.1232,  0.5070],\n",
       "          [-0.8024, -0.1824,  0.1630,  ...,  0.4806,  0.1115,  0.3375],\n",
       "          ...,\n",
       "          [-0.6579,  0.0999,  0.4524,  ...,  0.4763, -0.7529, -0.1294],\n",
       "          [ 0.3774, -0.1221, -1.1118,  ..., -0.1665,  0.5325, -0.3628],\n",
       "          [-0.2749, -0.2171, -0.5670,  ..., -0.1113,  0.0711, -0.0443]]]),\n",
       " tensor([[[ 0.2405, -0.1409, -0.1571,  ...,  0.0893, -0.1792,  0.0927],\n",
       "          [ 0.1499,  0.5117,  0.0604,  ...,  0.0830, -0.4050,  0.5482],\n",
       "          [-0.6971, -0.1413,  0.4801,  ...,  0.4826,  0.2082,  0.5188],\n",
       "          ...,\n",
       "          [-0.4415, -0.0017,  0.6341,  ...,  0.6850, -0.8352, -0.1639],\n",
       "          [ 0.1677, -0.2636, -1.1067,  ..., -0.4242,  0.3447,  0.0864],\n",
       "          [-0.2754, -0.3467, -0.6411,  ..., -0.1590, -0.0448, -0.0824]]]),\n",
       " tensor([[[ 0.3130, -0.1439, -0.2255,  ...,  0.1162, -0.1925,  0.0876],\n",
       "          [ 0.0538,  0.4609,  0.2630,  ...,  0.0667, -0.1796,  0.5095],\n",
       "          [-0.5503, -0.3464,  0.3649,  ...,  0.4720,  0.4046,  0.3193],\n",
       "          ...,\n",
       "          [-0.1517,  0.0556,  0.6331,  ...,  0.9215, -0.8649, -0.0506],\n",
       "          [-0.1019, -0.1725, -0.5118,  ..., -0.0917,  0.3672,  0.5342],\n",
       "          [-0.1303, -0.1651, -0.5917,  ..., -0.0656, -0.0698, -0.0368]]]),\n",
       " tensor([[[ 0.5157, -0.2409, -0.4674,  ..., -0.1142, -0.2981,  0.0633],\n",
       "          [ 0.4047,  0.3053,  0.2055,  ..., -0.2538, -0.2810,  0.6254],\n",
       "          [-0.3770, -0.2636,  0.5321,  ...,  0.4061,  0.2935,  0.3556],\n",
       "          ...,\n",
       "          [-0.1643,  0.7882,  0.5458,  ...,  0.7121, -1.0576,  0.1073],\n",
       "          [-0.1487, -0.1258, -0.3179,  ..., -0.3398,  0.3536,  0.8663],\n",
       "          [ 0.0079, -0.2838, -0.4978,  ..., -0.1521, -0.1181,  0.0989]]]),\n",
       " tensor([[[ 0.7141, -0.1320, -0.5163,  ..., -0.0425, -0.6218, -0.1161],\n",
       "          [ 0.7508,  0.4558,  0.1901,  ..., -0.4988, -0.4820,  0.5501],\n",
       "          [-0.2588, -0.0623,  0.4306,  ...,  0.0869,  0.1005,  0.4729],\n",
       "          ...,\n",
       "          [-0.2600,  0.7507,  0.5912,  ...,  0.8477, -1.4127,  0.1079],\n",
       "          [-0.1677, -0.3566, -0.6416,  ..., -0.5092,  0.3258,  1.0875],\n",
       "          [ 0.0957, -0.2325, -0.3176,  ..., -0.0627, -0.1127, -0.0041]]]),\n",
       " tensor([[[ 0.8266, -0.0506, -0.8271,  ...,  0.0957, -0.7302,  0.1177],\n",
       "          [ 0.7500,  0.4270, -0.0796,  ..., -0.2676, -0.8472,  0.5121],\n",
       "          [-0.4233, -0.0807,  0.3638,  ..., -0.0998,  0.3149,  0.4576],\n",
       "          ...,\n",
       "          [-0.5113,  0.8266,  0.8289,  ...,  0.5681, -0.9538,  0.2903],\n",
       "          [-0.3349, -0.6249, -0.6715,  ..., -0.7968,  0.4426,  1.3654],\n",
       "          [ 0.0083, -0.2493, -0.3733,  ..., -0.1229, -0.0077,  0.1439]]]),\n",
       " tensor([[[ 0.2384,  0.3259, -0.6756,  ..., -0.2010, -0.1729,  0.4073],\n",
       "          [-0.0366,  0.0800, -0.7680,  ..., -0.1070, -1.2407,  0.9647],\n",
       "          [-0.4404, -0.0905,  0.1851,  ...,  0.0407,  0.0929,  0.5966],\n",
       "          ...,\n",
       "          [-0.4928,  0.7419,  0.7040,  ...,  0.5500, -0.9031,  0.3327],\n",
       "          [-0.4714, -0.5001, -0.7695,  ..., -0.8135,  0.3546,  1.5608],\n",
       "          [-0.0557, -0.2235, -0.3792,  ..., -0.1547, -0.0168,  0.2146]]]),\n",
       " tensor([[[ 3.7226e-01,  5.6976e-01, -8.1802e-01,  ..., -5.7947e-01,\n",
       "            2.4505e-02,  5.2101e-01],\n",
       "          [-5.3903e-01,  1.4524e-01, -4.1975e-01,  ...,  2.1749e-01,\n",
       "           -1.0601e+00,  1.0030e+00],\n",
       "          [-2.7857e-01,  5.4977e-02,  2.7805e-01,  ...,  2.7531e-02,\n",
       "            1.1521e-01,  1.8069e-01],\n",
       "          ...,\n",
       "          [-2.3699e-01,  6.2394e-01,  6.0401e-01,  ...,  6.5308e-01,\n",
       "           -8.9490e-01,  4.7452e-01],\n",
       "          [-1.5150e-01, -3.6748e-01, -5.9640e-01,  ..., -1.3057e+00,\n",
       "            3.0131e-01,  1.8449e+00],\n",
       "          [-9.4634e-02, -3.4674e-01, -2.5163e-01,  ..., -2.2725e-01,\n",
       "            1.6468e-03,  2.6479e-01]]]),\n",
       " tensor([[[ 2.8482e-01,  6.1937e-01, -1.1200e+00,  ..., -4.4963e-01,\n",
       "           -1.3265e-01,  4.6209e-01],\n",
       "          [-2.7361e-01, -1.3391e-04, -4.6859e-01,  ...,  3.4488e-01,\n",
       "           -7.8427e-01,  9.8354e-01],\n",
       "          [-3.0894e-01,  3.2277e-02,  7.2952e-02,  ...,  2.2438e-01,\n",
       "            1.7700e-01,  1.1367e-01],\n",
       "          ...,\n",
       "          [ 2.4611e-01,  8.1659e-01,  5.4566e-01,  ...,  9.2498e-01,\n",
       "           -1.3029e+00,  3.3256e-01],\n",
       "          [-6.3766e-02, -4.7016e-01, -9.1238e-01,  ..., -1.1652e+00,\n",
       "            2.5162e-01,  1.6734e+00],\n",
       "          [-1.3741e-01, -1.2425e-01, -2.0126e-01,  ..., -1.5894e-01,\n",
       "           -1.3922e-03,  1.4095e-01]]]),\n",
       " tensor([[[ 0.1045,  0.7456, -2.3218,  ..., -0.5164,  0.0762,  0.4004],\n",
       "          [-0.3510,  0.0597, -0.4061,  ...,  0.9417, -0.6412,  0.8083],\n",
       "          [ 0.2919,  0.1690, -0.3439,  ...,  0.7772,  0.2620,  0.3743],\n",
       "          ...,\n",
       "          [ 0.0983,  1.0093,  0.1080,  ...,  0.5298, -0.9998,  0.6438],\n",
       "          [ 0.2383, -0.6134, -0.9425,  ..., -1.5169,  0.2573,  1.5352],\n",
       "          [-0.0418,  0.0051, -0.1187,  ..., -0.0810, -0.0144,  0.0381]]]),\n",
       " tensor([[[ 0.0870,  0.6522, -2.2073,  ..., -0.4857, -0.0323,  0.3641],\n",
       "          [ 0.1041, -0.1410,  0.0888,  ...,  0.5287, -0.7457,  0.3543],\n",
       "          [ 0.2509,  0.5288, -0.1159,  ...,  1.2474,  0.0421,  0.0670],\n",
       "          ...,\n",
       "          [-0.1623,  1.2064, -0.2750,  ...,  0.7096, -0.7821,  0.2858],\n",
       "          [-0.0864, -0.4516, -1.7421,  ..., -1.3189, -0.2205,  0.9978],\n",
       "          [-0.0351, -0.0191, -0.0871,  ..., -0.0805, -0.0430,  0.0132]]]),\n",
       " tensor([[[-0.1356,  0.9651, -2.0822,  ..., -0.4696,  0.1090,  0.2570],\n",
       "          [ 0.1459, -0.0109,  0.4076,  ...,  0.4713, -0.7107, -0.1490],\n",
       "          [ 0.7075,  0.2322, -0.0402,  ...,  1.1100,  0.6469, -0.2761],\n",
       "          ...,\n",
       "          [-0.0730,  1.2919, -0.0543,  ...,  0.7020, -0.8467,  0.7312],\n",
       "          [-0.0740, -0.1935, -1.6364,  ..., -1.3830,  0.0211,  0.8840],\n",
       "          [-0.0439, -0.0126, -0.0903,  ..., -0.0818, -0.0350,  0.0051]]]),\n",
       " tensor([[[-0.4271,  0.7438, -2.0034,  ..., -0.2380,  0.1592, -0.0623],\n",
       "          [ 0.3278,  0.2822,  0.4810,  ...,  0.8641, -0.5698, -0.2064],\n",
       "          [ 0.3555,  0.2548,  0.2239,  ...,  0.7638,  0.9443, -0.3782],\n",
       "          ...,\n",
       "          [ 0.0325,  1.2191,  0.0325,  ...,  0.3558, -0.7196,  0.8299],\n",
       "          [-0.1567, -0.4755, -1.6711,  ..., -1.2656,  0.2928,  0.3414],\n",
       "          [-0.0233,  0.0080, -0.0719,  ..., -0.0478, -0.0143,  0.0273]]]),\n",
       " tensor([[[-0.0338,  0.6637, -1.6910,  ..., -0.2092,  0.4864,  0.0783],\n",
       "          [ 0.1119,  0.1141,  0.8685,  ...,  0.9869, -0.6137, -0.3551],\n",
       "          [-0.2345,  0.2701,  0.3089,  ...,  0.3324,  0.6837, -0.3783],\n",
       "          ...,\n",
       "          [-0.0543,  1.1798, -0.2462,  ...,  0.6143, -0.3634,  0.8528],\n",
       "          [ 0.4496, -0.6171, -1.3860,  ..., -1.0406,  0.4827,  0.0103],\n",
       "          [-0.0301, -0.0516, -0.0900,  ..., -0.0514, -0.0438, -0.0177]]]),\n",
       " tensor([[[ 0.1195,  0.5521, -1.4877,  ...,  0.1191,  0.0892,  0.2304],\n",
       "          [ 0.0111,  0.0214,  0.6992,  ...,  0.8413, -0.4709, -0.3590],\n",
       "          [ 0.0031,  0.0778,  0.6745,  ...,  0.6084,  0.3918, -0.8832],\n",
       "          ...,\n",
       "          [-0.2722,  1.6582, -0.3246,  ...,  0.7695, -0.2300,  0.5764],\n",
       "          [ 0.3769, -0.5392, -1.7162,  ..., -0.8646,  0.3464,  0.0719],\n",
       "          [-0.0305, -0.0573, -0.0847,  ..., -0.0741, -0.0216, -0.0282]]]),\n",
       " tensor([[[ 0.0630,  0.1751, -1.4495,  ..., -0.2081,  0.1671,  0.1909],\n",
       "          [-0.1275,  0.0739,  0.3907,  ...,  0.7967, -0.1504, -0.1272],\n",
       "          [-0.0205, -0.1741,  0.4718,  ...,  0.3995,  0.7748, -0.4195],\n",
       "          ...,\n",
       "          [-0.2187,  1.3197, -0.4515,  ...,  0.6937, -0.0628,  0.6728],\n",
       "          [ 0.0693, -0.6718, -1.4852,  ..., -0.4954,  0.4408,  0.0978],\n",
       "          [ 0.0573, -0.2559,  0.0620,  ...,  0.0257, -0.0635, -0.0077]]]),\n",
       " tensor([[[ 0.2357,  0.0658, -1.0853,  ..., -0.0374, -0.3035,  0.0928],\n",
       "          [-0.0860,  0.1970,  0.2172,  ...,  1.2277, -0.2704,  0.4664],\n",
       "          [-0.0852,  0.0781,  0.4236,  ...,  0.6673,  1.0677, -0.1724],\n",
       "          ...,\n",
       "          [-0.2985,  1.2072, -0.1516,  ...,  0.8921,  0.1818,  0.8471],\n",
       "          [-0.1307, -0.8535, -1.9102,  ..., -0.4733,  0.3434,  0.0724],\n",
       "          [-0.0153, -0.0923, -0.0045,  ..., -0.0489, -0.0253,  0.0295]]]),\n",
       " tensor([[[ 0.1408, -0.2221, -1.1843,  ...,  0.0397, -0.5670,  0.4658],\n",
       "          [ 0.3573,  0.2551,  0.0530,  ...,  1.2099, -0.1241,  0.6465],\n",
       "          [ 0.3755, -0.1750,  0.2569,  ...,  1.1297,  0.4340, -0.2618],\n",
       "          ...,\n",
       "          [-0.0535,  1.1708, -0.0808,  ...,  1.0998,  0.2935,  0.8316],\n",
       "          [ 0.0810, -0.4902, -2.0075,  ..., -0.2618,  0.5114, -0.5384],\n",
       "          [ 0.0073, -0.0263, -0.0410,  ..., -0.0360, -0.0182,  0.0220]]]),\n",
       " tensor([[[ 0.4668, -0.1969, -1.0739,  ...,  0.0150, -0.6229,  0.3458],\n",
       "          [ 0.3384,  0.2892, -0.1437,  ...,  1.2784, -0.0642,  0.9192],\n",
       "          [ 0.4584, -0.2651, -0.2199,  ...,  1.3298,  0.7787, -0.0282],\n",
       "          ...,\n",
       "          [ 0.0770,  0.9474,  0.0807,  ...,  0.9435,  0.2241,  0.7683],\n",
       "          [-0.1117, -0.2677, -2.0899,  ..., -0.2171,  0.9808, -0.8769],\n",
       "          [ 0.0071,  0.0077, -0.0192,  ..., -0.0264, -0.0169,  0.0239]]]),\n",
       " tensor([[[ 2.0923e-01, -5.0003e-01, -1.5052e+00,  ..., -2.9717e-01,\n",
       "           -9.3176e-01,  3.8053e-01],\n",
       "          [ 4.2821e-02,  1.3251e-02, -2.9063e-01,  ...,  1.0381e+00,\n",
       "           -2.0418e-01,  1.1632e+00],\n",
       "          [ 4.2325e-01, -2.0761e-01, -2.2788e-01,  ...,  1.0701e+00,\n",
       "            2.9394e-01,  6.5412e-02],\n",
       "          ...,\n",
       "          [ 1.6981e-01,  6.0966e-01,  2.5195e-01,  ...,  6.3087e-01,\n",
       "            2.9113e-01,  5.7067e-01],\n",
       "          [-7.0012e-01, -4.0824e-03, -2.1922e+00,  ..., -3.7175e-01,\n",
       "            1.2390e+00, -1.1130e+00],\n",
       "          [ 3.8488e-02, -1.6726e-03, -1.6014e-02,  ..., -3.1930e-02,\n",
       "           -3.6640e-02,  1.6189e-02]]]),\n",
       " tensor([[[ 0.1514, -1.1748, -1.8220,  ..., -0.6149, -0.7679, -0.1942],\n",
       "          [-0.0936, -0.1445, -0.3129,  ...,  1.0854, -0.0349,  0.8387],\n",
       "          [ 0.6113,  0.0270, -0.0876,  ...,  1.3234,  0.3268,  0.1097],\n",
       "          ...,\n",
       "          [ 0.3411,  0.4910,  0.0894,  ...,  0.4892,  0.2491,  0.3484],\n",
       "          [-0.7756, -0.1568, -2.2654,  ..., -0.1054,  1.5570, -1.1211],\n",
       "          [-0.0148,  0.0273, -0.0653,  ..., -0.0189,  0.0082, -0.0679]]]),\n",
       " tensor([[[-0.4862, -0.3656, -1.3070,  ..., -1.2058,  0.1330, -0.2796],\n",
       "          [-0.3486, -0.2704, -0.3909,  ...,  0.8101, -0.0585,  0.8511],\n",
       "          [ 0.2463, -0.0902,  0.0132,  ...,  1.1968,  0.2786,  0.2841],\n",
       "          ...,\n",
       "          [ 0.3576,  0.2832, -0.1150,  ...,  0.5568,  0.1606,  0.2814],\n",
       "          [-1.3296, -0.1085, -2.2602,  ..., -0.0093,  2.0460, -0.9614],\n",
       "          [-0.0115, -0.0168, -0.0359,  ..., -0.0183,  0.0156, -0.0078]]]),\n",
       " tensor([[[-0.0972, -0.2136, -0.3256,  ..., -0.5415, -0.6636,  0.0294],\n",
       "          [-0.4817, -0.4640, -0.2206,  ...,  0.3141, -0.0049,  0.6424],\n",
       "          [-0.2269, -0.1001, -0.1190,  ...,  0.4294,  0.1401,  0.4921],\n",
       "          ...,\n",
       "          [-0.0183,  0.1221, -0.1733,  ...,  0.3006,  0.1561,  0.3533],\n",
       "          [-0.9472, -0.1931, -1.3968,  ..., -0.1003,  1.2266, -0.4975],\n",
       "          [ 0.6205,  0.2137, -0.1056,  ..., -0.5697, -0.5324, -0.1985]]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12レイヤー*\n",
    "\n",
    "encoded_layers[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cpu')\n",
    "segments_tensors = segments_tensors.to('cpu')\n",
    "model.to('cpu')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    last_layers, _ = model(tokens_tensor, segments_tensors,output_all_encoded_layers=False)\n",
    "    #最終層だけ取り出す。\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "# assert len(encoded_layers) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (768) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b55656b5ec5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (768) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "torch.allclose(encoded_layers[-1],last_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_layers[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いろいろな文の内部表現を取り出したい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"[CLS] I like unko! [SEP] can I input several sentencies? [SEP] ok? [SEP]\"\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_layers[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
