{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1. ロジスティック回帰の実装と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. シグモイド関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# シグモイドの微分形は手実装\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x) *(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. データセットの設定と重みの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#二次元で考える\n",
    "# ORに相当するような出力(xのどれかが1ならyは1)\n",
    "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "train_y = np.array([[1], [1], [0], [1]])\n",
    "test_X, test_y = train_X, train_y\n",
    "\n",
    "# weights\n",
    "W = np.random.uniform(low=-0.08, high=0.08, size=(2, 1)).astype('float32')\n",
    "b = np.zeros(1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is\n",
      " [[-0.04935689]\n",
      " [ 0.0195374 ]] \n",
      "\n",
      "b is [0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"W is\\n\",W,\"\\n\\nb is\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train関数とtest関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 誤差関数\n",
    "* 負の対数尤度関数 (Negative Loglikelihood Function）\n",
    "* 交差エントロピー誤差関数ともいう\n",
    "\n",
    "$$ E ( {\\bf \\theta} ) =  -\\sum^N_{i=1} \\left[ t_i \\log y ({\\bf x}_i ; {\\bf \\theta}) + (1 - t_i) \\log \\{ 1 - y ({\\bf x}_i ; {\\bf \\theta}) \\}\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global: 3\n",
      "not global: 10\n",
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ngb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d1ad28bb5cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtry_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ちゃんとここでエラーが出る\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ngb' is not defined"
     ]
    }
   ],
   "source": [
    "def try_global():\n",
    "    global num\n",
    "    num=3\n",
    "    ngb=10\n",
    "    print(\"global:\",num)\n",
    "    print(\"not global:\",ngb)\n",
    "\n",
    "try_global()\n",
    "print(num)\n",
    "print(ngb) #ちゃんとここでエラーが出る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x, t, eps=1.0):\n",
    "    \"\"\"\n",
    "    一回だけパラメーターを更新する関数\n",
    "    \"\"\"\n",
    "    #グローバル変数名空間でW,bという名前の変数を扱う(今回はすでに宣言されているためそれを弄ることになる)\n",
    "    global W, b # to access variables that defined outside of this function.\n",
    "    \n",
    "    # Forward Propagation\n",
    "    y = sigmoid(np.matmul(x, W) + b)\n",
    "    \n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "    #予測と教師信号から損失関数を計算\n",
    "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
    "    delta = y-t\n",
    "    \n",
    "    #微分したものに基づいてパラメーター更新\n",
    "    # Update Parameters\n",
    "    dW = np.matmul(x.T, delta)\n",
    "    db = np.matmul(np.ones(len(x)), delta)\n",
    "    W = W - eps*dW #暗示的なreturn\n",
    "    b = b - eps*db\n",
    "\n",
    "    return cost\n",
    "\n",
    "def test(x, t):\n",
    "    # Test Cost\n",
    "    y = sigmoid(np.matmul(x, W) + b)\n",
    "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "[[0.99799688]\n",
      " [0.99798893]\n",
      " [0.00499169]\n",
      " [0.99999998]]\n"
     ]
    }
   ],
   "source": [
    "# Epoch\n",
    "for epoch in range(1000):\n",
    "    # Online Learning\n",
    "    for x, y in zip(train_X, train_y):\n",
    "        cost = train(x[np.newaxis, :], y[np.newaxis, :])\n",
    "    cost, pred_y = test(test_X, test_y)\n",
    "\n",
    "print(train_y,end=\"\\n\\n\")\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2. 活性化関数とその微分の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. シグモイド関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ソフトマックス関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/np.sum(exp_x, axis=1, keepdims=True)\n",
    "    #次のセル参照\n",
    "\n",
    "\n",
    "def deriv_softmax(x):\n",
    "    return softmax(x)*(1 - softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "[3 7]\n",
      "\n",
      "[[3]\n",
      " [7]]\n"
     ]
    }
   ],
   "source": [
    "arr=np.array([[1,2],[3,4]])\n",
    "print(arr,end=\"\\n\\n\")\n",
    "print(arr.sum(axis=1),end=\"\\n\\n\")\n",
    "print(arr.sum(axis=1,keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tanh関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def deriv_tanh(x):\n",
    "    return 1 - tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題3. 多層パーセプトロンの実装と学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データセットの設定と重みの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XOR\n",
    "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "train_y = np.array([[1], [1], [0], [0]])\n",
    "test_X, test_y = train_X, train_y\n",
    "\n",
    "# Layer1 weights\n",
    "W1 = np.random.uniform(low=-0.08, high=0.08, size=(2, 3)).astype('float32')\n",
    "b1 = np.zeros(3).astype('float32')\n",
    "\n",
    "# Layer2 weights\n",
    "W2 = np.random.uniform(low=-0.08, high=0.08, size=(3, 1)).astype('float32')\n",
    "b2 = np.zeros(1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.train関数とtest関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 誤差関数\n",
    "* 負の対数尤度関数 (Negative Loglikelihood Function）\n",
    "* 交差エントロピー誤差関数ともいう\n",
    "\n",
    "$$ E ( {\\bf \\theta} ) =  -\\sum^N_{i=1} \\left[ t_i \\log y ({\\bf x}_i ; {\\bf \\theta}) + (1 - t_i) \\log \\{ 1 - y ({\\bf x}_i ; {\\bf \\theta}) \\}\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x, t, eps=1.0):\n",
    "    global W1, b1, W2, b2 # to access variables that defined outside of this function.\n",
    "    \n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = sigmoid(u2)\n",
    "    \n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "    y = z2\n",
    "    cost = np.sum(-t*np.log(y) - (1 - t)*np.log(1 - y))\n",
    "    delta_2 = y - t # Layer2 delta\n",
    "    delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) # Layer1 delta\n",
    "\n",
    "    # Update Parameters Layer1\n",
    "    dW1 = np.matmul(x.T, delta_1)\n",
    "    db1 = np.matmul(np.ones(len(x)), delta_1)\n",
    "    W1 = W1 - eps*dW1\n",
    "    b1 = b1 - eps*db1\n",
    "    \n",
    "    # Update Parameters Layer2\n",
    "    dW2 = np.matmul(z1.T, delta_2)\n",
    "    db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
    "    W2 = W2 - eps*dW2\n",
    "    b2 = b2 - eps*db2\n",
    "\n",
    "    return cost\n",
    "\n",
    "def test(x, t):\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = sigmoid(u2)\n",
    "    \n",
    "    y = z2\n",
    "    \n",
    "    # Test Cost\n",
    "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99788042]\n",
      " [0.99785468]\n",
      " [0.00182329]\n",
      " [0.0034414 ]]\n"
     ]
    }
   ],
   "source": [
    "# Epoch\n",
    "for epoch in range(2000):\n",
    "    # Online Learning\n",
    "    for x, y in zip(train_X, train_y):\n",
    "        cost = train(x[np.newaxis, :], y[np.newaxis, :])\n",
    "    cost, pred_y = test(test_X, test_y)\n",
    "\n",
    "print(pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
