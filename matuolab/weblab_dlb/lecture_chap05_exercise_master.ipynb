{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Tensorflowの基礎を学ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#tensorflowをインポート\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensorflowの概観"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では, 基本的に以下の流れで機械学習モデルを構築します.\n",
    "\n",
    "1. プレースホルダーと変数の設定\n",
    "2. グラフの構築\n",
    "3. 誤差関数の設定\n",
    "4. 重みの更新ルールの設定\n",
    "5. `tf.Session()`を開始して学習\n",
    "6. 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 線形回帰の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:: 10, cost:: 0.464\n",
      "iteration:: 20, cost:: 0.135\n",
      "iteration:: 30, cost:: 0.040\n",
      "iteration:: 40, cost:: 0.012\n",
      "iteration:: 50, cost:: 0.003\n",
      "iteration:: 60, cost:: 0.001\n",
      "iteration:: 70, cost:: 0.000\n",
      "iteration:: 80, cost:: 0.000\n",
      "iteration:: 90, cost:: 0.000\n",
      "iteration:: 100, cost:: 0.000\n",
      "pred_y: [13.003278]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "#これをすれば、メモリ上で構築されているグラフがリセットされるので、新たに始めたいときはこれをする。\n",
    "\n",
    "# Step1. プレースホルダー・変数の設定\n",
    "## placeholder: データを流し込む変数. データ毎に変わる\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "## Variable: 変数(重み). データ間で共有される\n",
    "w = tf.Variable(0.0, name='w')\n",
    "b = tf.Variable(0.0, name='b')\n",
    "\n",
    "# Step2. グラフの構築\n",
    "y = w*x + b\n",
    "#shapeを考慮するといましているのは、ただ単に、1次関数を組んで、単回帰しているだけ。\n",
    "\n",
    "# Step3. 誤差関数の設定\n",
    "cost = tf.reduce_mean((y - t)**2)\n",
    "\n",
    "# Step4. 重みの更新則の設定\n",
    "gw, gb = tf.gradients(cost, [w, b]) # 勾配の計算\n",
    "# tf.gradients(関数,　その関数の引数とする変数名(テンソル))\n",
    "# 今回ならば損失関数を構成するwとbについてのそれぞれの勾配が返される。\n",
    "\n",
    "updates = [\n",
    "    w.assign(w - 0.1*gw), # 勾配降下法\n",
    "    b.assign(b - 0.1*gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "# Step.5. 学習 (y = 2*x + 3)\n",
    "data_X = np.array([0., 1., 2., 3., 4.])\n",
    "data_y = np.array([3., 5., 7., 9., 11.])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重みの初期化\n",
    "for i in range(100):\n",
    "    # trainもtunしているのでwとbが更新されて次のループに入る。\n",
    "    _cost, _ = sess.run([cost, train], feed_dict={x: data_X, t: data_y})\n",
    "    if (i+1)%10==0:\n",
    "        print('iteration:: %d, cost:: %.3f' % (i+1, _cost))\n",
    "\n",
    "# Step6. 予測\n",
    "print('pred_y:', sess.run(y, feed_dict={x: [5]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. プレースホルダー・変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfには2種類の変数 (のようなもの) があります. それぞれ以下のように使い分けます."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.placeholder`: データ間で値が共有されない変数 (入力の`x`, 正解ラベルの `t` などに使用)\n",
    "- `tf.Variable` : データ間で値が共有される変数 (重みの `W`, `b` など更新されるものに使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.  `tf.placeholder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを流し込む入り口として使います.\n",
    "- 変数の型 (`tf.int32`, `tf.float32`) を指定する必要があります\n",
    "- 実行時にはデータを**`feed_dict`**で渡す必要があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"pow_1:0\", dtype=float32)\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "y = x**2\n",
    "print(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. `tf.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値がデータ間で共有されるので, まず初期値を与える必要があります."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全ての変数を初期化する場合は`tf.global_variables_initializer()`を使います.\n",
    "- 個別に変数を初期化する場合は`tf.variables_initializer()`を使い, 引数に初期化したい変数をリストで渡します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0.0, name='w')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     print(w.eval())#これはエラーになる#変数を初期化する前に評価しようとしているから\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(w.eval()) # print(sess.run(w))でも同じです\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([w]))\n",
    "    print(w.eval()) \n",
    "#     print(b.eval()) # 初期化していないので, エラーが出ます.\n",
    "print()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([w, b]))\n",
    "    print(w.eval())\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIは`numpy`と非常に似ています. また, `numpy`と**同じく要素毎に演算**が行われます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.7182817, 7.389056 ], dtype=float32), array([0.       , 0.6931472], dtype=float32), array([1.       , 1.4142135], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "exp_x = tf.exp(x)\n",
    "log_x = tf.log(x)\n",
    "sqrt_x = tf.sqrt(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([exp_x, log_x, sqrt_x], feed_dict={x: [1,2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ニューラルネットワーク用の関数は`tf.nn`以下にあります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7310586, 0.7615942, 1.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sigmoid_x = tf.nn.sigmoid(x)\n",
    "tanh_x = tf.nn.tanh(x)\n",
    "relu_x = tf.nn.relu(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([sigmoid_x, tanh_x, relu_x], feed_dict={x: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.mean, np.sum`等に対応するものは`tf.reduce_mean, tf.reduce_sum`等になります.\n",
    "- 引数`axis`で指定した軸に沿って演算を行います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.0, 4.5]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sum_x = tf.reduce_sum(x, 0)\n",
    "mean_x = tf.reduce_mean(x, 0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([sum_x, mean_x], feed_dict={x: np.arange(10)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 行列・テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np` の `dot`, `matmul` に対応するものは `tf.matmul` ですが, 少し挙動が違うので注意する必要があります."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. 行列積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.matmul` を使用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]] \n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "[[2. 2.]\n",
      " [2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "b = tf.ones([2,2])\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(a.eval(),\"\\n\",b.eval(),end=\"\\n\\n\")\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトルに対しても `tf.newaxis` などで**明示的に行列に変換する必要**があります."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[[2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "b = tf.ones(2)\n",
    "\n",
    "# c = tf.matmul(a, b) # エラー# 次元が合わないのでエラーになる\n",
    "c = tf.matmul(a, b[:, tf.newaxis])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(b.eval()  )\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```np```と同様に```tf```にも```einsum```があります. 3階以上のテンソルを含む計算はこれを用いるのがわかりやすくベターです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. 6.]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,3,4])\n",
    "b = tf.ones([2,3])\n",
    "\n",
    "c = tf.einsum('ijk,ij->k', a, b)\n",
    "#->の先で何も指定しないときはすべてをまとめて、0次元のテンソルとする。\n",
    "sum_c = tf.einsum('ijk,ij->', a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())\n",
    "    print(sum_c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. 条件・比較演算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 条件の前にpythonのラムダ式についての復習\n",
    "```\n",
    "#lambda式の形式\n",
    "(lambda 引数:処理内容)(実際に入れる引数)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "a1=3\n",
    "a2=4\n",
    "print((lambda x,y: x*y)(a1, a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda: a2-a1)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exfunc = lambda: a2-a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exfunc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要は簡易的な関数宣言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflowにおいて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件演算子は\n",
    "- `tf.cond(condition, if true(関数), if false(関数))`\n",
    "です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(x > y, lambda: x - y, lambda: y - x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較演算子は\n",
    "- `tf.equal`\n",
    "- `tf.greater` (>でも可)\n",
    "- `tf.less` (<でも可)\n",
    "\n",
    "などを使います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(tf.greater(x, y), lambda: x - y, lambda: y - x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他の言語のfor文に対応するものは`tf.scan`ですが, これはRNNの回で扱います."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 勾配 (微分) の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`をつかうことで微分を計算することができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0]\n",
      "[4.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = x**2\n",
    "\n",
    "grads = tf.gradients(y, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x: 1.}))\n",
    "    print(sess.run(grads, feed_dict={x: 2.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二引数(`xs`)に複数の変数を指定すると, それぞれに対する偏微分をリストで返します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 64.0]\n",
      "[18.0, 512.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32, name='x1')\n",
    "x2 = tf.placeholder(tf.float32, name='x2')\n",
    "y = 3*x1**2 + 2*x2**4\n",
    "\n",
    "grads = tf.gradients(y, [x1, x2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x1: 1, x2: 2}))\n",
    "    print(sess.run(grads, feed_dict={x1: 3, x2: 4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0]\n",
      "[18.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32, name='x1')\n",
    "x2 = tf.placeholder(tf.float32, name='x2')\n",
    "y = 3*x1**2 + 2*x2**4\n",
    "\n",
    "grads = tf.gradients(y, [x1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x1: 1, x2: 2}))\n",
    "    print(sess.run(grads, feed_dict={x1: 3, x2: 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 変数 (Variable) の更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assign, assign_add, assign_sub` メソッドにより行います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "\n",
    "add_one = a.assign_add(1.) #1を足すというオペレータをつくる\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        print(sess.run(add_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の更新をまとめる場合は `tf.group` を使用します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1.0,  b: 9.0\n",
      "a: 2.0,  b: 8.0\n",
      "a: 3.0,  b: 7.0\n",
      "a: 4.0,  b: 6.0\n",
      "a: 5.0,  b: 5.0\n",
      "a: 6.0,  b: 4.0\n",
      "a: 7.0,  b: 3.0\n",
      "a: 8.0,  b: 2.0\n",
      "a: 9.0,  b: 1.0\n",
      "a: 10.0,  b: 0.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "b = tf.Variable(10.0, name='b')\n",
    "\n",
    "add_one = a.assign_add(1.) \n",
    "sub_one = b.assign_sub(1.)#1ずつ引くオペレーターを作っている\n",
    "\n",
    "updates = [\n",
    "    add_one,\n",
    "    sub_one\n",
    "]\n",
    "\n",
    "# まとめる\n",
    "train = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(train)\n",
    "        print('a:', a.eval(), end=',  ')\n",
    "        print('b:', b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. TensorBoardによるグラフの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowで計算グラフの構築方法を扱ってきましたが, ここでは構築した計算グラフの可視化をし, 視覚的に捉えてみましょう.\n",
    "\n",
    "計算グラフを表示するには, tensorboard.py [\\[引用元\\]](http://qiita.com/kegamin/items/887c7dfe8bbb76197741) を読み込む必要があります.\n",
    "\n",
    "tensorboard.pyをimportしたら, `show_graph`関数にグラフを渡すことで可視化できます.\n",
    "\n",
    "可視化結果はインタラクティブな表示になるので, 拡大や移動, 詳細表示等を試してみましょう."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run([c], feed_dict={a:2, b:3}))\n",
    "\n",
    "# tb.show_graph(sess.graph)    # 単純な足し算のグラフの表示 (がしたいが...)\n",
    "\n",
    "#ここが動かないので下記で修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.14646809085434243&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.14646809085434243&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorboard as tb\n",
    "#import tensorflow_graph_in_jupyter as tb\n",
    "from tensorflow_graph_in_jupyter import show_graph\n",
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([c], feed_dict={a:2, b:3}))\n",
    "\n",
    "show_graph(tf.get_default_graph())    # 単純な足し算のグラフの表示 (がしたいが...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. グラフの管理と整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1. デフォルトグラフ\n",
    "\n",
    "グラフが表示されたものの, 大変ごちゃごちゃしており, 足し算以外のグラフも表示されてしまったかと思います.\n",
    "\n",
    "これは, 今回の演習でこれまでに実行された計算グラフがすべて表示されてしまっているためです.\n",
    "\n",
    "TensorFlowでは何も指定しなければ, デフォルトグラフと呼ばれるグラフ上に計算グラフを構築します.\n",
    "\n",
    "一度計算グラフ上に配置されたグラフは, そのグラフを使うか使わないかにかかわらず, 全てリセットされることなく蓄積されていきます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったオペレーション\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables() # Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.  `tf.reset_default_graph`関数によるリセット\n",
    "\n",
    "このままでは, 使わないゴミリソースが蓄積してしまう上, TensorBoardで可視化する際にも無関係のグラフまで表示され見づらくなってしまいます.\n",
    "\n",
    "特にJupyter等のインタラクティブな環境では全体で1セッションなので, こうした傾向が顕著であり, 途中でリセット処理を書くことが重要です.\n",
    "\n",
    "対処法としては, 毎回新しくグラフを構築する際に `tf.reset_default_graph()` によりグラフをリセットすることです.\n",
    "\n",
    "こうすることで毎回クリーンな状態でグラフを構築していくことができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "5.0\n",
      "[<tf.Operation 'Placeholder' type=Placeholder>, <tf.Operation 'Placeholder_1' type=Placeholder>, <tf.Operation 'add' type=Add>]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.09726331595199544&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.09726331595199544&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "print(tf.get_default_graph().get_operations())\n",
    "print(tf.global_variables())\n",
    "\n",
    "# 再び足し算のグラフを構築・表示\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c, feed_dict={a:2, b:3}))\n",
    "\n",
    "print(tf.get_default_graph().get_operations())\n",
    "print(tf.global_variables())\n",
    "# tb.show_graph(tf.Session().graph)\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. 複雑なグラフの整理\n",
    "\n",
    "グラフを表示したとき, 各ノードの名前は基本的に自動で割り振られます.\n",
    "\n",
    "ただ, これでは少し規模が大きくなるだけですぐにコードとの対応をつけるのが難しくなります.\n",
    "\n",
    "そこで, 定数・変数やプレースホルダーなどには `name`引数を明示的に指定し, ノード名を与えておきましょう."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3419377954651631&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;range/start&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;pow&quot;\\n  input: &quot;range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3419377954651631&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 線形回帰の例\n",
    "\n",
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# プレースホルダーと変数の宣言\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "W = tf.Variable(tf.random_uniform([5,3], -1.0, 1.0), name='W')\n",
    "b = tf.Variable(tf.zeros([3]), name='b')\n",
    "\n",
    "# グラフの構築\n",
    "y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "# 誤差関数の定義\n",
    "loss = tf.reduce_mean((y - t)**2, name='loss')\n",
    "\n",
    "# tb.show_graph(tf.Session().graph)\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "かなりコードと対応がつき, 見やすくなりました.\n",
    "\n",
    "しかし, 今後より大規模なグラフを扱う際には, 今のままでは頂点が余りにも多くなってしまい, 見ずらくなってしまいます.\n",
    "\n",
    "そこで頂点をまとめることを考えると, これには tf.name_scope 関数を用います.\n",
    "\n",
    "まとめられた頂点は, カーソルをかざすと出てくる右上のプラスマークをクリックすることで展開することができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9600119842934555&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;variables/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;variables/random_uniform/max&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;variables/random_uniform/RandomUniform&quot;\\n  input: &quot;variables/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;variables/random_uniform/mul&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/W&quot;\\n  input: &quot;variables/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/b&quot;\\n  input: &quot;variables/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;variables/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;model/MatMul&quot;\\n  input: &quot;variables/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;model/y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;training/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;training/range/start&quot;\\n  input: &quot;training/Rank&quot;\\n  input: &quot;training/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;training/Square&quot;\\n  input: &quot;training/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9600119842934555&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "with tf.name_scope('variables'):\n",
    "    W = tf.Variable(tf.random_uniform([5,3], -1.0, 1.0), name='W')\n",
    "    b = tf.Variable(tf.zeros([3]), name='b')\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    loss = tf.reduce_mean(tf.square(y - t), name='loss')\n",
    "\n",
    "# tb.show_graph(tf.Session().graph)\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4. グラフの切り分け\n",
    "\n",
    "デフォルトグラフではなく, 明示的にグラフオブジェクトを作成し, その上にグラフを構築していくことでグラフ環境を他と分けることもできます.\n",
    "\n",
    "これは複数のグラフを構築していきたいときなどに便利です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "g0 = tf.get_default_graph() # デフォルトグラフオブジェクトを取得することも可能\n",
    "\n",
    "##----------------------------------------------------##\n",
    "g1 = tf.Graph() # グラフオブジェクトの作成1\n",
    "\n",
    "a = tf.constant(2, name='a0') # これはdefault graphへの配置になるので注意\n",
    "b = a**a\n",
    "\n",
    "# with文で、指定したグラフオブジェクトにグラフを構築することが可能\n",
    "with g1.as_default(): # デフォルトに設定した上で, グラフを構築・操作\n",
    "    a = tf.constant(2, name='a')\n",
    "    b = a**a\n",
    "\n",
    "g2 = tf.Graph() # グラフオブジェクトの作成2\n",
    "\n",
    "with g2.as_default(): # デフォルトに設定し, グラフを構築\n",
    "    a = tf.constant(4, name='a')\n",
    "    x = tf.constant(3, name='x')\n",
    "    y = a**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9754266880703274&quot;).pbtxt = 'node {\\n  name: &quot;a0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a0&quot;\\n  input: &quot;a0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9754266880703274&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tb.show_graph(g0)\n",
    "show_graph(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.13502939947957704&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;a&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.13502939947957704&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    print(sess.run(b))\n",
    "# tb.show_graph(g1)\n",
    "\n",
    "show_graph(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6679945201932778&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6679945201932778&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    print(sess.run(y))\n",
    "# tb.show_graph(g2)\n",
    "show_graph(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※注意\n",
    "\n",
    "ここで紹介している方法は, グラフの表示のみに対応しています.\n",
    "\n",
    "TensorBoardそのものはグラフ以外にも, 学習中のパラメータの変化など様々な可視化に対応しているのですが,\n",
    "\n",
    "Jupyter上では対応が進んでおらず, TensorBoardをフルに活用できないのです.\n",
    "\n",
    "Jupyterを用いずに手元の環境で行う場合, およそ次の方法でフルのTensorBoardを使用できます. (tensorboard.pyは不要です)\n",
    "\n",
    "1. tf.Session 中で tf.summary.FileWriter 関数によりログの出力を設定\n",
    "\n",
    "2. ターミナルで \"tensorboard --logdir= (ログの出力先) \" を実行\n",
    "\n",
    "3. localhost:6006にブラウザからアクセス\n",
    "\n",
    "より興味が湧いた方はぜひ手元の環境で下の公式情報を参考に他の可視化についても試してください.\n",
    "\n",
    "参考:\n",
    "- https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "- https://www.tensorflow.org/get_started/embedding_viz\n",
    "- https://www.tensorflow.org/get_started/graph_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 自動微分を使ったロジスティック回帰の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットに OR を用いてロジスティック回帰を実装してみましょう. パラメータの勾配の計算には `tf` の自動微分機能 `tf.gradients` を使ってみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 予測確率の計算\n",
    "$$\n",
    "    y = \\sigma({\\bf W}^{\\mathrm{T}}{\\bf x} + {\\bf b})\n",
    "$$\n",
    "- 誤差関数: 交差エントロピー\n",
    "$$\n",
    "    E = -\\sum^N_{i=1} [t_i \\log y_i + (1 - t_i) \\log (1 - y_i) ]\n",
    "$$\n",
    "- 勾配降下法によるパラメータの更新 ($\\epsilon$: 学習率)\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf W}^{(l)} &\\leftarrow {\\bf W}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf W}^{(l)}}  \\\\\n",
    "    {\\bf b}^{(l)} &\\leftarrow {\\bf b}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf b}^{(l)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34381974\n",
      "0.26790747\n",
      "0.21812478\n",
      "0.18308824\n",
      "0.15722485\n",
      "0.1374165\n",
      "0.12180197\n",
      "0.10920583\n",
      "0.09884994\n",
      "0.09019965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.821003304779427&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;s*J\\\\275\\\\350\\\\014\\\\240<&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/W&quot;\\n  input: &quot;variables/W/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/b&quot;\\n  input: &quot;variables/b/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;variables/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;variables/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value/clip_value_min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.000000013351432e-10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value/clip_value_max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value&quot;\\n  op: &quot;ClipByValue&quot;\\n  input: &quot;y&quot;\\n  input: &quot;cost/clip_by_value/clip_value_min&quot;\\n  input: &quot;cost/clip_by_value/clip_value_max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;cost/clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;t&quot;\\n  input: &quot;cost/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;cost/sub/x&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;cost/sub_1/x&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value_1/clip_value_min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.000000013351432e-10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value_1/clip_value_max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/clip_by_value_1&quot;\\n  op: &quot;ClipByValue&quot;\\n  input: &quot;cost/sub_1&quot;\\n  input: &quot;cost/clip_by_value_1/clip_value_min&quot;\\n  input: &quot;cost/clip_by_value_1/clip_value_max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/Log_1&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;cost/clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;cost/sub&quot;\\n  input: &quot;cost/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;cost/mul&quot;\\n  input: &quot;cost/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;cost/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;cost/range/start&quot;\\n  input: &quot;cost/Rank&quot;\\n  input: &quot;cost/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;cost/add&quot;\\n  input: &quot;cost/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;cost/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;update/gradients/Shape&quot;\\n  input: &quot;update/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Neg_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;update/gradients/Fill&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;cost/range&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/add&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/range/start&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Size&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape_1&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/range&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/mod&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/DynamicStitch&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/Neg_grad/Neg&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Reshape&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Shape_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape_2&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Shape_3&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Maximum_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Maximum_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Prod_1&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Maximum_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/floordiv_1&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Prod&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Maximum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/floordiv_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Tile&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/add_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/truediv&quot;\\n  input: &quot;update/gradients/cost/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/add_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/Mean_grad/truediv&quot;\\n  input: &quot;update/gradients/cost/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/add_grad/Sum_1&quot;\\n  input: &quot;update/gradients/cost/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/gradients/cost/add_grad/Reshape&quot;\\n  input: &quot;cost/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Mul&quot;\\n  input: &quot;update/gradients/cost/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;t&quot;\\n  input: &quot;update/gradients/cost/add_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Mul_1&quot;\\n  input: &quot;update/gradients/cost/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Sum_1&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/gradients/cost/add_grad/Reshape_1&quot;\\n  input: &quot;cost/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Mul&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;cost/sub&quot;\\n  input: &quot;update/gradients/cost/add_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Mul_1&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Sum_1&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Log_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;cost/clip_by_value&quot;\\n  input: &quot;^update/gradients/cost/mul_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Log_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/gradients/cost/mul_grad/Reshape_1&quot;\\n  input: &quot;update/gradients/cost/Log_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Log_1_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;cost/clip_by_value_1&quot;\\n  input: &quot;^update/gradients/cost/mul_1_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/Log_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/gradients/cost/mul_1_grad/Reshape_1&quot;\\n  input: &quot;update/gradients/cost/Log_1_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;update/gradients/cost/Log_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape_3&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;y&quot;\\n  input: &quot;cost/clip_by_value/clip_value_min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;y&quot;\\n  input: &quot;cost/clip_by_value/clip_value_max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/BroadcastGradientArgs_1&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/LogicalOr&quot;\\n  op: &quot;LogicalOr&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Less&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Greater&quot;\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/LogicalOr&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/zeros&quot;\\n  input: &quot;update/gradients/cost/Log_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Less&quot;\\n  input: &quot;update/gradients/cost/Log_grad/mul&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Greater&quot;\\n  input: &quot;update/gradients/cost/Log_grad/mul&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/BroadcastGradientArgs_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Select_1&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Sum_1&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Sum_2&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Select_2&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/BroadcastGradientArgs_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_grad/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Sum_2&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cost/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;update/gradients/cost/Log_1_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_3&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;cost/sub_1&quot;\\n  input: &quot;cost/clip_by_value_1/clip_value_min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;cost/sub_1&quot;\\n  input: &quot;cost/clip_by_value_1/clip_value_max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/BroadcastGradientArgs_1&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/LogicalOr&quot;\\n  op: &quot;LogicalOr&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Less&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Greater&quot;\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/LogicalOr&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/zeros&quot;\\n  input: &quot;update/gradients/cost/Log_1_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Less&quot;\\n  input: &quot;update/gradients/cost/Log_1_grad/mul&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Select_2&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Greater&quot;\\n  input: &quot;update/gradients/cost/Log_1_grad/mul&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Select&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/BroadcastGradientArgs_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Select_1&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Sum_1&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Sum_2&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Select_2&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/BroadcastGradientArgs_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/clip_by_value_1_grad/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Sum_2&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Shape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Shape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Reshape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Sum&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_1_grad/Reshape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/cost/sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Neg&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;update/gradients/cost/clip_by_value_grad/Reshape&quot;\\n  input: &quot;update/gradients/cost/sub_1_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@update/gradients/cost/clip_by_value_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/y_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;y&quot;\\n  input: &quot;update/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;update/gradients/add_grad/Shape&quot;\\n  input: &quot;update/gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/y_grad/SigmoidGrad&quot;\\n  input: &quot;update/gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/add_grad/Sum&quot;\\n  input: &quot;update/gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;update/gradients/y_grad/SigmoidGrad&quot;\\n  input: &quot;update/gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;update/gradients/add_grad/Sum_1&quot;\\n  input: &quot;update/gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;update/gradients/add_grad/Reshape&quot;\\n  input: &quot;variables/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/gradients/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;update/gradients/add_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/mul/x&quot;\\n  input: &quot;update/gradients/MatMul_grad/MatMul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;variables/W&quot;\\n  input: &quot;update/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/mul_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update/mul_1/x&quot;\\n  input: &quot;update/gradients/add_grad/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/AssignAdd_1&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;variables/b&quot;\\n  input: &quot;update/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^update/AssignAdd&quot;\\n  input: &quot;^update/AssignAdd_1&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^variables/W/Assign&quot;\\n  input: &quot;^variables/b/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.821003304779427&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "# Step1. プレースホルダーと変数の定義\n",
    "## プレースホルダー\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "## 変数\n",
    "# rngは乱数のseed\n",
    "with tf.name_scope('variables'):\n",
    "    W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(2, 1)).astype('float32'), name='W')\n",
    "    b = tf.Variable(np.zeros(1).astype('float32'), name='b')\n",
    "\n",
    "# Step2. グラフの構築\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b, name=\"y\")\n",
    "\n",
    "# Step3. 誤差関数の定義\n",
    "# cost = -tf.reduce_mean(t*tf.log(y) + (1 - t)*tf.log(1 - y))\n",
    "# 大きくなりすぎたり小さくなりすぎないように勾配をクリッピングしている\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(t*tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - t)*tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0))) # tf.log(0)によるnanを防ぐ\n",
    "\n",
    "# Step4. 更新則の設定\n",
    "with tf.name_scope(\"update\"):\n",
    "    gW, gb = tf.gradients(cost, [W, b])\n",
    "    updates = [\n",
    "        W.assign_add(-0.01*gW),\n",
    "        b.assign_add(-0.01*gb)\n",
    "    ]\n",
    "    train = tf.group(*updates)\n",
    "\n",
    "# OR\n",
    "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "train_y = np.array([[1], [1], [0], [1]])\n",
    "\n",
    "# Step5. 学習\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        _cost, _ = sess.run([cost, train], feed_dict={x: train_X, t: train_y})\n",
    "        if (i+1)%1000==0:\n",
    "            print(_cost)\n",
    "\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 自動微分を使った多層パーセプトロン (Multilayer perceptron, MLP) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットに MNIST を用いて MLP を実装してみましょう. パラメータの勾配の計算には `tf` の自動微分機能 `tf.gradients` を使ってみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 順伝播\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf u}^{(1)} &= {\\bf W}^{(1)\\mathrm{T}} {\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "    {\\bf z}^{(1)} &= \\sigma({\\bf u}^{(1)}) \\\\\n",
    "    {\\bf u}^{(2)} &= {\\bf W}^{(2)\\mathrm{T}} {\\bf z^{(1)}} + {\\bf b}^{(2)} \\\\\n",
    "    {\\bf y} &= \\mathrm{softmax} ({\\bf u}^{(2)})\n",
    "\\end{align*}\n",
    "$$\n",
    "- 誤差関数: 多クラス交差エントロピー\n",
    "$$\n",
    "    E = -\\sum^N_{i=1} \\sum^K_{k=1} t_{ik} \\log y_{ik}\n",
    "$$\n",
    "- 勾配降下法によるパラメータの更新 ($\\epsilon$: 学習率)\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf W}^{(l)} &\\leftarrow {\\bf W}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf W}^{(l)}}  \\\\\n",
    "    {\\bf b}^{(l)} &\\leftarrow {\\bf b}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf b}^{(l)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-60316898eb39>:39: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/masaki/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "EPOCH:: 1, Validation cost: 1482.452, Validation F1: 0.916\n",
      "EPOCH:: 2, Validation cost: 1174.606, Validation F1: 0.937\n",
      "EPOCH:: 3, Validation cost: 928.269, Validation F1: 0.949\n",
      "EPOCH:: 4, Validation cost: 789.311, Validation F1: 0.958\n",
      "EPOCH:: 5, Validation cost: 730.649, Validation F1: 0.959\n",
      "EPOCH:: 6, Validation cost: 680.376, Validation F1: 0.962\n",
      "EPOCH:: 7, Validation cost: 611.669, Validation F1: 0.966\n",
      "EPOCH:: 8, Validation cost: 567.511, Validation F1: 0.969\n",
      "EPOCH:: 9, Validation cost: 546.956, Validation F1: 0.970\n",
      "EPOCH:: 10, Validation cost: 539.901, Validation F1: 0.972\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "# Step1. プレースホルダーと変数の定義\n",
    "## Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "## 変数\n",
    "W1 = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(784, 200)).astype('float32'), name='W1')\n",
    "b1 = tf.Variable(np.zeros(200).astype('float32'), name='b1')\n",
    "W2 = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(200, 10)).astype('float32'), name='W2')\n",
    "b2 = tf.Variable(np.zeros(10).astype('float32'), name='b2')\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "# Step2. グラフの定義\n",
    "u1 = tf.matmul(x, W1) + b1\n",
    "z1 = tf.nn.sigmoid(u1)\n",
    "u2 = tf.matmul(z1, W2) + b2\n",
    "y = tf.nn.softmax(u2)\n",
    "\n",
    "# Step3. 誤差関数の定義\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(y)))\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(tf.clip_by_value(y, 1e-10, 1.0)))) # tf.log(0)によるnanを防ぐ\n",
    "\n",
    "# Step4. 更新則の設定\n",
    "gW1, gb1, gW2, gb2 = tf.gradients(cost, params)\n",
    "updates = [\n",
    "    W1.assign_add(-0.01*gW1),\n",
    "    b1.assign_add(-0.01*gb1),\n",
    "    W2.assign_add(-0.01*gW2),\n",
    "    b2.assign_add(-0.01*gb2)\n",
    "]\n",
    "\n",
    "train = tf.group(*updates)\n",
    "\n",
    "valid = tf.argmax(y, 1)\n",
    "\n",
    "# MNIST\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "mnist_X, mnist_y = mnist.train.images, mnist.train.labels\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(mnist_X, mnist_y, test_size=0.1, random_state=random_state)\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0] // batch_size\n",
    "\n",
    "# Step5. 学習\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "        pred_y, valid_cost = sess.run([valid, cost], feed_dict={x: valid_X, t: valid_y})\n",
    "        print('EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' % (epoch + 1, valid_cost, f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 参考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Tensorflow Documentation](https://www.tensorflow.org/api_docs/)\n",
    "2. [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/mandelbrot)\n",
    "2. [CS 20SI: Tensorflow for Deep Leaning Research](http://web.stanford.edu/class/cs20si/)\n",
    "3. [CS224d: Tensorflow Tutorial](https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いや、生tensorflow記述量多すぎ！！！！"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 123.18181799999999,
   "position": {
    "height": "40px",
    "left": "6.09082px",
    "right": "20px",
    "top": "636px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
